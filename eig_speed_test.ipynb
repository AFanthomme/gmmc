{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For N = 10, numpy took 2.27e-04 pm 4.30e-04\n",
      "For N = 10, pytorch on CPU took 1.39e-04 pm 3.03e-04\n",
      "For N = 10, pytorch on GPU took 1.74e-01 pm 5.14e-01\n",
      "For N = 100, numpy took 7.19e-03 pm 1.37e-03\n",
      "For N = 100, pytorch on CPU took 2.44e-03 pm 1.41e-04\n",
      "For N = 100, pytorch on GPU took 8.41e-03 pm 9.89e-04\n",
      "For N = 200, numpy took 3.39e-02 pm 4.23e-03\n",
      "For N = 200, pytorch on CPU took 1.15e-02 pm 3.68e-04\n",
      "For N = 200, pytorch on GPU took 1.94e-02 pm 1.11e-03\n",
      "For N = 350, numpy took 8.51e-02 pm 1.34e-03\n",
      "For N = 350, pytorch on CPU took 3.29e-02 pm 9.85e-04\n",
      "For N = 350, pytorch on GPU took 4.05e-02 pm 1.70e-03\n",
      "For N = 400, numpy took 1.13e-01 pm 4.61e-03\n",
      "For N = 400, pytorch on CPU took 4.17e-02 pm 9.60e-04\n",
      "For N = 400, pytorch on GPU took 4.84e-02 pm 7.83e-04\n",
      "For N = 500, numpy took 1.84e-01 pm 6.38e-03\n",
      "For N = 500, pytorch on CPU took 6.74e-02 pm 1.76e-03\n",
      "For N = 500, pytorch on GPU took 7.25e-02 pm 2.09e-03\n",
      "For N = 600, numpy took 3.03e-01 pm 9.48e-03\n",
      "For N = 600, pytorch on CPU took 1.20e-01 pm 1.84e-03\n",
      "For N = 600, pytorch on GPU took 1.21e-01 pm 2.27e-03\n",
      "For N = 650, numpy took 3.49e-01 pm 5.92e-03\n",
      "For N = 650, pytorch on CPU took 1.42e-01 pm 4.51e-03\n",
      "For N = 650, pytorch on GPU took 1.42e-01 pm 7.40e-03\n",
      "For N = 1000, numpy took 8.91e-01 pm 1.39e-02\n",
      "For N = 1000, pytorch on CPU took 3.21e-01 pm 9.50e-03\n",
      "For N = 1000, pytorch on GPU took 2.83e-01 pm 7.30e-03\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch as tch\n",
    "import time\n",
    "\n",
    "# Compare performance of np and tch on matrix eigenvalue decomposition\n",
    "\n",
    "def test_np(N):\n",
    "    J = np.random.normal(scale=1./np.sqrt(N), size=(N,N)).astype(dtype=np.float32)\n",
    "    J = (J + J.T) / np.sqrt(2)\n",
    "    spectrum, _ = np.linalg.eig(J)\n",
    "\n",
    "def test_tch_cpu(N):\n",
    "    J = tch.normal(tch.zeros([N,N], dtype=tch.float32), 1./np.sqrt(N))\n",
    "    J = (J + J.t()) / np.sqrt(2)\n",
    "    spectrum, _ = tch.eig(J)\n",
    "\n",
    "def test_tch_gpu(N):\n",
    "    J = tch.normal(tch.zeros([N,N], dtype=tch.float32).cuda(), 1./np.sqrt(N))\n",
    "    J = (J + J.t()) / np.sqrt(2)\n",
    "    spectrum, _ = tch.eig(J)\n",
    "\n",
    "def profile(func):\n",
    "    plop = np.zeros(10)\n",
    "    for i in range(10):\n",
    "        tic = time.time()\n",
    "        func()\n",
    "        plop[i] = time.time() - tic\n",
    "    return np.mean(plop), np.std(plop)\n",
    "\n",
    "\n",
    "for N in [10, 100, 200, 350, 400, 500, 600, 650, 1000]:\n",
    "\n",
    "\n",
    "    np_lambda = lambda: test_np(N)\n",
    "    tch_cpu_lambda = lambda: test_tch_cpu(N)\n",
    "    tch_gpu_lambda = lambda: test_tch_gpu(N)\n",
    "\n",
    "    if N <= 1000:\n",
    "        m, v = profile(np_lambda)\n",
    "        print('For N = {}, numpy took {:.2e} pm {:.2e}'.format(N, m, v))\n",
    "    m, v = profile(tch_cpu_lambda)\n",
    "    print('For N = {}, pytorch on CPU took {:.2e} pm {:.2e}'.format(N, m, v))\n",
    "    m, v = profile(tch_gpu_lambda)\n",
    "    print('For N = {}, pytorch on GPU took {:.2e} pm {:.2e}'.format(N, m, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion :\n",
    "Should use tch_cpu for small matrices (3x speedup wrt np), and gpu only when very large matrices (N>~600)\n",
    "Numpy is never a good choice..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For N = 10, numpy took 7.09e-04 pm 1.73e-03\n",
      "For N = 10, pytorch on CPU took 3.32e-04 pm 7.94e-04\n",
      "For N = 10, pytorch on GPU took 1.69e-01 pm 4.98e-01\n",
      "For N = 100, numpy took 1.91e-03 pm 9.26e-04\n",
      "For N = 100, pytorch on CPU took 4.61e-04 pm 5.89e-05\n",
      "For N = 100, pytorch on GPU took 3.38e-03 pm 1.30e-04\n",
      "For N = 200, numpy took 4.80e-03 pm 2.15e-04\n",
      "For N = 200, pytorch on CPU took 1.86e-03 pm 6.34e-05\n",
      "For N = 200, pytorch on GPU took 6.15e-03 pm 1.67e-04\n",
      "For N = 350, numpy took 1.55e-02 pm 1.09e-03\n",
      "For N = 350, pytorch on CPU took 5.25e-03 pm 2.43e-04\n",
      "For N = 350, pytorch on GPU took 9.66e-03 pm 1.49e-04\n",
      "For N = 400, numpy took 2.03e-02 pm 7.06e-04\n",
      "For N = 400, pytorch on CPU took 6.74e-03 pm 2.28e-04\n",
      "For N = 400, pytorch on GPU took 1.09e-02 pm 6.58e-05\n",
      "For N = 500, numpy took 3.07e-02 pm 1.18e-03\n",
      "For N = 500, pytorch on CPU took 1.04e-02 pm 2.03e-04\n",
      "For N = 500, pytorch on GPU took 1.36e-02 pm 3.34e-04\n",
      "For N = 600, numpy took 4.82e-02 pm 1.09e-03\n",
      "For N = 600, pytorch on CPU took 1.48e-02 pm 3.24e-04\n",
      "For N = 600, pytorch on GPU took 1.71e-02 pm 8.70e-04\n",
      "For N = 650, numpy took 5.91e-02 pm 1.05e-03\n",
      "For N = 650, pytorch on CPU took 1.74e-02 pm 3.08e-04\n",
      "For N = 650, pytorch on GPU took 2.01e-02 pm 8.56e-04\n",
      "For N = 1000, numpy took 1.72e-01 pm 3.32e-03\n",
      "For N = 1000, pytorch on CPU took 4.81e-02 pm 1.74e-03\n",
      "For N = 1000, pytorch on GPU took 4.59e-02 pm 1.41e-03\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch as tch\n",
    "import time\n",
    "\n",
    "# Compare performance of np and tch on matrix eigenvalue decomposition for symmetric matrices\n",
    "\n",
    "def test_np(N):\n",
    "    J = np.random.normal(scale=1./np.sqrt(N), size=(N,N)).astype(dtype=np.float32)\n",
    "    J = (J + J.T) / np.sqrt(2)\n",
    "    spectrum, _ = np.linalg.eigh(J)\n",
    "\n",
    "def test_tch_cpu(N):\n",
    "    J = tch.normal(tch.zeros([N,N], dtype=tch.float32), 1./np.sqrt(N))\n",
    "    J = (J + J.t()) / np.sqrt(2)\n",
    "    spectrum, _ = tch.symeig(J)\n",
    "\n",
    "def test_tch_gpu(N):\n",
    "    J = tch.normal(tch.zeros([N,N], dtype=tch.float32).cuda(), 1./np.sqrt(N))\n",
    "    J = (J + J.t()) / np.sqrt(2)\n",
    "    spectrum, _ = tch.symeig(J)\n",
    "\n",
    "def profile(func):\n",
    "    plop = np.zeros(10)\n",
    "    for i in range(10):\n",
    "        tic = time.time()\n",
    "        func()\n",
    "        plop[i] = time.time() - tic\n",
    "    return np.mean(plop), np.std(plop)\n",
    "\n",
    "\n",
    "for N in [10, 100, 200, 350, 400, 500, 600, 650, 1000]:\n",
    "\n",
    "    np_lambda = lambda: test_np(N)\n",
    "    tch_cpu_lambda = lambda: test_tch_cpu(N)\n",
    "    tch_gpu_lambda = lambda: test_tch_gpu(N)\n",
    "\n",
    "    if N <= 1000:\n",
    "        m, v = profile(np_lambda)\n",
    "        print('For N = {}, numpy took {:.2e} pm {:.2e}'.format(N, m, v))\n",
    "    m, v = profile(tch_cpu_lambda)\n",
    "    print('For N = {}, pytorch on CPU took {:.2e} pm {:.2e}'.format(N, m, v))\n",
    "    m, v = profile(tch_gpu_lambda)\n",
    "    print('For N = {}, pytorch on GPU took {:.2e} pm {:.2e}'.format(N, m, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conclusion :\n",
    "Always use symeig, MUCH faster on large matrices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda_base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
